{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6637e53a-1040-4001-a56a-da5da8d15ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 07:16:28.409848: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-03 07:16:28.450245: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-03 07:16:29.035021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['builtins', 'builtins', 'nibabel', 'numpy', 'os', 'cv2', 'types', 'tensorflow', 'tensorflow.keras.backend', 'matplotlib.pyplot']\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import types\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, BatchNormalization, Activation\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----DEBUG-----\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield val.__name__\n",
    "print(list(imports()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d9c9166-35d9-4a10-a19f-9ad33187145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train IDs:  250\n",
      "['sub-strokecase0001', 'sub-strokecase0002', 'sub-strokecase0003', 'sub-strokecase0004', 'sub-strokecase0005']\n",
      "Mask IDs:  250\n",
      "['sub-strokecase0001', 'sub-strokecase0002', 'sub-strokecase0003', 'sub-strokecase0004', 'sub-strokecase0005']\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "TRAIN_DATASET_PATH = '/home/user/Tf_script/dataset/ISLES_2022/rawdata/'\n",
    "TRAINMask_DATASET_PATH = '/home/user/Tf_script/dataset/ISLES_2022/derivatives/'\n",
    "\n",
    "# Get dataset details\n",
    "trainfolders = os.listdir(TRAIN_DATASET_PATH)\n",
    "train_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "# train_ids = [train_directories[i][48:66] for i in range(len(train_directories))]\n",
    "train_directory_startindex = train_directories[0].find(\"sub\")\n",
    "train_ids = sorted([train_directories[i][train_directory_startindex:] for i in range(len(train_directories))])\n",
    "\n",
    "maskfolders = os.listdir(TRAINMask_DATASET_PATH)\n",
    "mask_directories = [f.path for f in os.scandir(TRAINMask_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "# mask_ids = [mask_directories[i][48:66] for i in range(len(mask_directories))]\n",
    "mask_id_startindex = mask_directories[0].find(\"sub\")\n",
    "mask_ids = sorted([mask_directories[i][mask_id_startindex:] for i in range(len(mask_directories))])\n",
    "\n",
    "# -----DEBUG-----\n",
    "print(\"Train IDs: \", len(train_ids))\n",
    "# print(train_ids[0], \"to\", train_ids[-1])\n",
    "print(sorted(train_ids)[:5])\n",
    "print(\"Mask IDs: \", len(mask_ids))\n",
    "# print(mask_ids[0], \"to\", mask_ids[-1])\n",
    "print(sorted(mask_ids)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14ba8ff-1ddc-4157-9b7b-d00629e8c9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:  112 X 112\n"
     ]
    }
   ],
   "source": [
    "# train_test_ids, val_ids, train_test_mask, val_mask = train_test_split(train_ids, mask_ids, test_size=0.15, random_state=42)\n",
    "# train_ids, test_ids, train_mask, test_mask = train_test_split(train_test_ids, train_test_mask, test_size=0.15, random_state=42)\n",
    "train_test_ids, val_ids,train_test_mask, val_mask = train_test_split(train_ids,mask_ids,test_size=0.2,random_state = 32) \n",
    "train_ids,  test_ids, train_mask , test_mask = train_test_split(train_test_ids,train_test_mask,test_size=0.2,random_state = 32)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "IMG_SIZE = 112\n",
    "\n",
    "# -----DEBUG-----\n",
    "print(\"Dimensions: \", (\"{} X {}\".format(IMG_SIZE, IMG_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7a7d0f-c731-4171-9a8e-b97d18e531b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    y_true_new = K.flatten(y_true)\n",
    "    y_pred_new = K.flatten(y_pred)\n",
    "    denominator = K.sum(y_true_new) + K.sum(y_pred_new)\n",
    "    numerator = K.sum(y_true_new * y_pred_new)\n",
    "    return (2 * numerator + 1) / (denominator + 1)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersec = K.sum(y_true * y_pred)\n",
    "    union = K.sum(y_true + y_pred)\n",
    "    return (intersec + 0.1) / (union - intersec + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb314a4-bf5c-4ebc-9290-56ddb4c7c42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  160\n",
      "Validation:  50\n",
      "Testing:  40\n"
     ]
    }
   ],
   "source": [
    "# Data generator class\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE, IMG_SIZE), batch_size=1, n_channels=1, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        X = []\n",
    "        y = []\n",
    "        for i in Batch_ids:\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i, 'ses-0001/dwi')\n",
    "            nii_files = [f for f in os.listdir(case_path) if f.endswith('.nii.gz')]\n",
    "\n",
    "            if not nii_files:\n",
    "                print(f\"No .nii.gz files found in {case_path}\")\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(case_path, nii_files[0])\n",
    "            dwi = nib.load(file_path).get_fdata()\n",
    "            dwi = scaler.fit_transform(dwi.reshape(-1, dwi.shape[-1])).reshape(dwi.shape)\n",
    "            slices = dwi.shape[2]\n",
    "            X_case = np.zeros((slices, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "            case_path2 = os.path.join(TRAINMask_DATASET_PATH, i)\n",
    "            data_path_2 = os.path.join(case_path2 + '/ses-0001', f'{i}_ses-0001_msk.nii.gz')\n",
    "\n",
    "            if not os.path.exists(data_path_2):\n",
    "                print(f\"Mask file not found: {data_path_2}\")\n",
    "                continue\n",
    "\n",
    "            msk = nib.load(data_path_2).get_fdata()\n",
    "            msk_slices = msk.shape[2]\n",
    "            y_case = np.zeros((msk_slices, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "            for j in range(slices):\n",
    "                X_case[j, :, :, 0] = cv2.resize(dwi[:, :, j], (IMG_SIZE, IMG_SIZE))\n",
    "                y_case[j, :, :] = cv2.resize(msk[:, :, j], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "            X.append(X_case)\n",
    "            y.append(y_case)\n",
    "\n",
    "        X = np.concatenate(X, axis=0).astype(np.float32)\n",
    "        y = np.concatenate(y, axis=0).astype(np.float32)\n",
    "        mask = tf.one_hot(y, depth=1)\n",
    "        return X, mask\n",
    "\n",
    "training_generator = DataGenerator(train_ids, batch_size=1)  # Reduce batch size\n",
    "val_generator = DataGenerator(val_ids, batch_size=1)\n",
    "test_generator = DataGenerator(test_ids, batch_size=1)\n",
    "\n",
    "# -----DEBUG-----\n",
    "print(\"Training: \", len(training_generator))\n",
    "print(\"Validation: \", len(val_generator))\n",
    "print(\"Testing: \", len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1f78f10-f52f-470f-a975-75ce7d220d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from math import log2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def mlp(x, cf):\n",
    "    x = L.Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
    "    x = L.Dropout(cf[\"dropout_rate\"])(x)\n",
    "    x = L.Dense(cf[\"hidden_dim\"])(x)\n",
    "    x = L.Dropout(cf[\"dropout_rate\"])(x)\n",
    "    return x\n",
    "\n",
    "def transformer_encoder(x, cf):\n",
    "    skip_1 = x\n",
    "    x = L.LayerNormalization()(x)\n",
    "    x = L.MultiHeadAttention(\n",
    "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
    "    )(x, x)\n",
    "    x = L.Add()([x, skip_1])\n",
    "\n",
    "    skip_2 = x\n",
    "    x = L.LayerNormalization()(x)\n",
    "    x = mlp(x, cf)\n",
    "    x = L.Add()([x, skip_2])\n",
    "\n",
    "    return x\n",
    "\n",
    "def conv_block(x, num_filters, kernel_size=3):\n",
    "    x = L.Conv2D(num_filters, kernel_size=kernel_size, padding=\"same\")(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def deconv_block(x, num_filters, strides=2):\n",
    "    x = L.Conv2DTranspose(num_filters, kernel_size=2, padding=\"same\", strides=strides)(x)\n",
    "    return x\n",
    "\n",
    "def build_unetr_2d(cf):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
    "    inputs = L.Input(input_shape) ## (None, 256, 3072)\n",
    "\n",
    "    \"\"\" Patch + Position Embeddings \"\"\"\n",
    "    patch_embed = L.Dense(cf[\"hidden_dim\"])(inputs) ## (None, 256, 768)\n",
    "\n",
    "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1) ## (256,)\n",
    "    pos_embed = L.Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
    "    x = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "    \"\"\" Transformer Encoder \"\"\"\n",
    "    skip_connection_index = [3, 6, 9, 12]\n",
    "    skip_connections = []\n",
    "\n",
    "    for i in range(1, cf[\"num_layers\"]+1, 1):\n",
    "        x = transformer_encoder(x, cf)\n",
    "\n",
    "        if i in skip_connection_index:\n",
    "            skip_connections.append(x)\n",
    "\n",
    "    \"\"\" CNN Decoder \"\"\"\n",
    "    z3, z6, z9, z12 = skip_connections\n",
    "\n",
    "    ## Reshaping\n",
    "    z0 = L.Reshape((cf[\"image_size\"], cf[\"image_size\"], cf[\"num_channels\"]))(inputs)\n",
    "\n",
    "    shape = (\n",
    "        cf[\"image_size\"]//cf[\"patch_size\"],\n",
    "        cf[\"image_size\"]//cf[\"patch_size\"],\n",
    "        cf[\"hidden_dim\"]\n",
    "    )\n",
    "    z3 = L.Reshape(shape)(z3)\n",
    "    z6 = L.Reshape(shape)(z6)\n",
    "    z9 = L.Reshape(shape)(z9)\n",
    "    z12 = L.Reshape(shape)(z12)\n",
    "\n",
    "    ## Additional layers for managing different patch sizes\n",
    "    total_upscale_factor = int(log2(cf[\"patch_size\"]))\n",
    "    upscale = total_upscale_factor - 4\n",
    "\n",
    "    if upscale >= 2: ## Patch size 16 or greater\n",
    "        z3 = deconv_block(z3, z3.shape[-1], strides=2**upscale)\n",
    "        z6 = deconv_block(z6, z6.shape[-1], strides=2**upscale)\n",
    "        z9 = deconv_block(z9, z9.shape[-1], strides=2**upscale)\n",
    "        z12 = deconv_block(z12, z12.shape[-1], strides=2**upscale)\n",
    "        # print(z3.shape, z6.shape, z9.shape, z12.shape)\n",
    "\n",
    "    if upscale < 0: ## Patch size less than 16\n",
    "        p = 2**abs(upscale)\n",
    "        z3 = L.MaxPool2D((p, p))(z3)\n",
    "        z6 = L.MaxPool2D((p, p))(z6)\n",
    "        z9 = L.MaxPool2D((p, p))(z9)\n",
    "        z12 = L.MaxPool2D((p, p))(z12)\n",
    "\n",
    "    ## Decoder 1\n",
    "    x = deconv_block(z12, 128)\n",
    "\n",
    "    s = deconv_block(z9, 128)\n",
    "    s = conv_block(s, 128)\n",
    "\n",
    "    x = L.Concatenate()([x, s])\n",
    "\n",
    "    x = conv_block(x, 128)\n",
    "    x = conv_block(x, 128)\n",
    "\n",
    "    ## Decoder 2\n",
    "    x = deconv_block(x, 64)\n",
    "\n",
    "    s = deconv_block(z6, 64)\n",
    "    s = conv_block(s, 64)\n",
    "    s = deconv_block(s, 64)\n",
    "    s = conv_block(s, 64)\n",
    "\n",
    "    x = L.Concatenate()([x, s])\n",
    "    x = conv_block(x, 64)\n",
    "    x = conv_block(x, 64)\n",
    "\n",
    "    ## Decoder 3\n",
    "    x = deconv_block(x, 32)\n",
    "\n",
    "    s = deconv_block(z3, 32)\n",
    "    s = conv_block(s, 32)\n",
    "    s = deconv_block(s, 32)\n",
    "    s = conv_block(s, 32)\n",
    "    s = deconv_block(s, 32)\n",
    "    s = conv_block(s, 32)\n",
    "\n",
    "    x = L.Concatenate()([x, s])\n",
    "    x = conv_block(x, 32)\n",
    "    x = conv_block(x, 32)\n",
    "\n",
    "    ## Decoder 4\n",
    "    x = deconv_block(x, 16)\n",
    "\n",
    "    s = conv_block(z0, 16)\n",
    "    s = conv_block(s, 16)\n",
    "\n",
    "    x = L.Concatenate()([x, s])\n",
    "    x = conv_block(x, 16)\n",
    "    x = conv_block(x, 16)\n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = L.Conv2D(1, kernel_size=1, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model(inputs, outputs, name=\"UNETR_2D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e15b311-f0da-42ca-90cf-12e0cf75e9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 112, 112, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 28, 28, 64)   1088        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 784, 64)      0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 784, 64)     0           ['reshape_5[0][0]']              \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_49 (LayerN  (None, 784, 64)     128         ['tf.__operators__.add_3[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (Multi  (None, 784, 64)     132672      ['layer_normalization_49[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 784, 64)      0           ['multi_head_attention_24[0][0]',\n",
      "                                                                  'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_50 (LayerN  (None, 784, 64)     128         ['add_48[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 784, 64)      4160        ['layer_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " dense_51 (Dense)               (None, 784, 64)      4160        ['dense_50[0][0]']               \n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 784, 64)      0           ['dense_51[0][0]',               \n",
      "                                                                  'add_48[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_51 (LayerN  (None, 784, 64)     128         ['add_49[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 784, 64)     132672      ['layer_normalization_51[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " add_50 (Add)                   (None, 784, 64)      0           ['multi_head_attention_25[0][0]',\n",
      "                                                                  'add_49[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 784, 64)     128         ['add_50[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 784, 64)      4160        ['layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 784, 64)      4160        ['dense_52[0][0]']               \n",
      "                                                                                                  \n",
      " add_51 (Add)                   (None, 784, 64)      0           ['dense_53[0][0]',               \n",
      "                                                                  'add_50[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 784, 64)     128         ['add_51[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_26 (Multi  (None, 784, 64)     132672      ['layer_normalization_53[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " add_52 (Add)                   (None, 784, 64)      0           ['multi_head_attention_26[0][0]',\n",
      "                                                                  'add_51[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 784, 64)     128         ['add_52[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 784, 64)      4160        ['layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 784, 64)      4160        ['dense_54[0][0]']               \n",
      "                                                                                                  \n",
      " add_53 (Add)                   (None, 784, 64)      0           ['dense_55[0][0]',               \n",
      "                                                                  'add_52[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 784, 64)     128         ['add_53[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_27 (Multi  (None, 784, 64)     132672      ['layer_normalization_55[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " add_54 (Add)                   (None, 784, 64)      0           ['multi_head_attention_27[0][0]',\n",
      "                                                                  'add_53[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_56 (LayerN  (None, 784, 64)     128         ['add_54[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 784, 64)      4160        ['layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 784, 64)      4160        ['dense_56[0][0]']               \n",
      "                                                                                                  \n",
      " add_55 (Add)                   (None, 784, 64)      0           ['dense_57[0][0]',               \n",
      "                                                                  'add_54[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_57 (LayerN  (None, 784, 64)     128         ['add_55[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_28 (Multi  (None, 784, 64)     132672      ['layer_normalization_57[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " add_56 (Add)                   (None, 784, 64)      0           ['multi_head_attention_28[0][0]',\n",
      "                                                                  'add_55[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_58 (LayerN  (None, 784, 64)     128         ['add_56[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 784, 64)      4160        ['layer_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 784, 64)      4160        ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      " add_57 (Add)                   (None, 784, 64)      0           ['dense_59[0][0]',               \n",
      "                                                                  'add_56[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_59 (LayerN  (None, 784, 64)     128         ['add_57[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_29 (Multi  (None, 784, 64)     132672      ['layer_normalization_59[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " add_58 (Add)                   (None, 784, 64)      0           ['multi_head_attention_29[0][0]',\n",
      "                                                                  'add_57[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_60 (LayerN  (None, 784, 64)     128         ['add_58[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 784, 64)      4160        ['layer_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 784, 64)      4160        ['dense_60[0][0]']               \n",
      "                                                                                                  \n",
      " add_59 (Add)                   (None, 784, 64)      0           ['dense_61[0][0]',               \n",
      "                                                                  'add_58[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_61 (LayerN  (None, 784, 64)     128         ['add_59[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_30 (Multi  (None, 784, 64)     132672      ['layer_normalization_61[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 784, 64)      0           ['multi_head_attention_30[0][0]',\n",
      "                                                                  'add_59[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_62 (LayerN  (None, 784, 64)     128         ['add_60[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 784, 64)      4160        ['layer_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 784, 64)      4160        ['dense_62[0][0]']               \n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 784, 64)      0           ['dense_63[0][0]',               \n",
      "                                                                  'add_60[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_63 (LayerN  (None, 784, 64)     128         ['add_61[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_31 (Multi  (None, 784, 64)     132672      ['layer_normalization_63[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " add_62 (Add)                   (None, 784, 64)      0           ['multi_head_attention_31[0][0]',\n",
      "                                                                  'add_61[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_64 (LayerN  (None, 784, 64)     128         ['add_62[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_64 (Dense)               (None, 784, 64)      4160        ['layer_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " dense_65 (Dense)               (None, 784, 64)      4160        ['dense_64[0][0]']               \n",
      "                                                                                                  \n",
      " add_63 (Add)                   (None, 784, 64)      0           ['dense_65[0][0]',               \n",
      "                                                                  'add_62[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_65 (LayerN  (None, 784, 64)     128         ['add_63[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 50176)        0           ['layer_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 512)          25690624    ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['dense_66[0][0]']               \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 1)            513         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,822,337\n",
      "Trainable params: 26,822,337\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (IMG_SIZE, IMG_SIZE, 1)\n",
    "num_classes = 1  # Binary classification\n",
    "model = ViT(input_shape, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a96ba9a1-230d-46ae-972b-9e41534ee1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 07:24:54.912715: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-08-03 07:25:04.158160: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: required broadcastable shapes\n",
      "2024-08-03 07:25:04.158228: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: required broadcastable shapes\n",
      "\t [[{{node add_3}}]]\n",
      "2024-08-03 07:25:04.158255: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: required broadcastable shapes\n",
      "2024-08-03 07:25:04.158285: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: required broadcastable shapes\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'add_3' defined at (most recent call last):\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1848780/2965651932.py\", line 10, in <module>\n      history = model.fit(training_generator,\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1055, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1149, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 691, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/tmp/ipykernel_1848780/457084516.py\", line 17, in iou\n      union = K.sum(y_true + y_pred)\nNode: 'add_3'\nrequired broadcastable shapes\n\t [[{{node add_3}}]] [Op:__inference_train_function_61904]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvit_brain_lesion_segmentation.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'add_3' defined at (most recent call last):\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1848780/2965651932.py\", line 10, in <module>\n      history = model.fit(training_generator,\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1055, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1149, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 691, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/tmp/ipykernel_1848780/457084516.py\", line 17, in iou\n      union = K.sum(y_true + y_pred)\nNode: 'add_3'\nrequired broadcastable shapes\n\t [[{{node add_3}}]] [Op:__inference_train_function_61904]"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coeff, iou])\n",
    "\n",
    "# Checkpoints and learning rate adjustments\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(training_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=250,\n",
    "                    steps_per_epoch=len(train_ids),\n",
    "                    callbacks=[checkpoint, reduce_lr, early_stopping])\n",
    "\n",
    "# Save the model\n",
    "model.save(\"vit_brain_lesion_segmentation.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
