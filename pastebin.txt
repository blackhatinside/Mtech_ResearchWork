Here's a detailed summary of the research project and ISLES22 dataset:

Research Project Overview:
The project focuses on brain lesion segmentation using class-aware augmentation techniques combined with an Attention U-Net architecture. The key objectives were:
- Addressing class imbalance and data scarcity in brain lesion datasets
- Implementing optimized segmentation through Attention U-Net
- Examining effects of various augmentation methods

ISLES22 Dataset Characteristics:
- Multi-center MRI dataset designed for stroke lesion segmentation
- 400 total cases (250 training, 150 test samples)
- Images in NIfTI format converted to PNG (112x112 pixels)
- Contains DWI (Diffusion-weighted imaging) scans with corresponding lesion masks
- Ground truth masks are binary (white for lesion, black for non-lesion)

Key Methodology:
1. Data Preprocessing:
- Conversion from NIfTI to PNG format
- Intensity normalization using Min-Max scaling
- Standardized image resizing to 112x112 pixels

2. Class-aware Augmentation:
The data was categorized into 5 classes based on lesion size:
- C1: 1-50 pixels (2477 images)
- C2: 51-100 pixels (637 images)
- C3: 101-150 pixels (413 images)
- C4: 151-200 pixels (253 images)
- C5: >200 pixels (1047 images)

Each class received specific augmentation strategies:
- Smaller lesions: More aggressive rotations and transformations
- Larger lesions: Conservative changes to preserve clinical validity

3. Results:
- Initial dataset expanded from 4,827 to 13,174 images
(c1 - 2477 images, c2 - 2548 images, c4 - 2530 images, c4 - 1047 images, c3 - 2478 images)
- Improved Dice score from 0.6651 to 0.7307 with augmentation
- Best performance achieved by U-Net with augmentation (0.7451 Dice score)

The project demonstrated that class-aware augmentation effectively addresses imbalance issues while maintaining clinical relevance, leading to improved segmentation accuracy especially for challenging lesion cases.

The ISLES22 dataset proved valuable for this research due to its:
- Diverse lesion characteristics (size, shape, location)
- Multi-vendor nature reflecting real clinical scenarios
- High-quality annotations
- Standardized evaluation metrics
- Public availability for reproducible research

The dataset's inherent challenges (class imbalance, lesion variability) made it ideal for testing advanced augmentation strategies and segmentation architectures.


import cv2
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import keras.backend as K

BASE_PATH = "/home/user/adithyaes/dataset/isles2022_png"
AUG_PATH = "/home/user/adithyaes/dataset/isles2022_png_aug"
INPUT_PATH = os.path.join(BASE_PATH, "input")
MASK_PATH = os.path.join(BASE_PATH, "mask")
AUG_INPUT_PATH = os.path.join(AUG_PATH, "input")
AUG_MASK_PATH = os.path.join(AUG_PATH, "mask")
OUTPUT_DIRECTORY = "./output/ISLESfolder"
os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)

IMG_SIZE = 112
BATCH_SIZE = 4  # 2
LEARNINGRATE = 0.001 # 0.0001
EPOCHS = 100 # 30
EARLYSTOPPING = 40 # 10
scaler = MinMaxScaler(feature_range=(-1, 1))  # Scale to match original nii range better

def dice_coeff(y_true, y_pred):
	y_true_f = K.flatten(y_true)
	y_pred_f = K.flatten(y_pred)
	intersection = K.sum(y_true_f * y_pred_f)
	return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)

def iou(y_true, y_pred):
	intersection = K.sum(y_true * y_pred)
	union = K.sum(y_true + y_pred)
	return (intersection + 0.1) / (union - intersection + 0.1)

def dice_loss(y_true, y_pred):
	return tf.keras.losses.binary_crossentropy(y_true, y_pred) + (1 - dice_coeff(y_true, y_pred))

def conv_block(inp, filters):
	x = Conv2D(filters, 3, padding='same', use_bias=False)(inp)
	x = BatchNormalization()(x)
	return Activation('relu')(x)

def attention_gate(x, g, filters):
	g1 = Conv2D(filters, 1)(g)
	x1 = Conv2D(filters, 1)(x)
	out = Activation('relu')(add([g1, x1]))
	out = Conv2D(1, 1, activation='sigmoid')(out)
	return multiply([x, out])

def get_case_ids(path):
	files = sorted([f for f in os.listdir(path) if f.endswith('.png')])
	return sorted(list({f.split('_')[1] for f in files}))

def load_and_preprocess(file_path, is_mask=False):
	img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
	img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
	if not is_mask:
		img = scaler.fit_transform(img.reshape(-1, 1)).reshape(img.shape)
	else:
		img = img / 255.0
	return img

class DataGenerator(tf.keras.utils.Sequence):
	def __init__(self, list_IDs, aug_ids=None, batch_size=BATCH_SIZE, shuffle=True):
		self.batch_size = batch_size
		self.list_IDs = list_IDs
		self.aug_ids = aug_ids if aug_ids is not None else []
		self.all_ids = list_IDs + self.aug_ids
		self.shuffle = shuffle
		self.on_epoch_end()

	def __len__(self):
		return int(np.floor(len(self.all_ids) / self.batch_size))

	def __getitem__(self, index):
		indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
		batch_ids = [self.all_ids[k] for k in indexes]
		return self.__data_generation(batch_ids)

	def on_epoch_end(self):
		self.indexes = np.arange(len(self.all_ids))
		if self.shuffle:
			np.random.shuffle(self.indexes)

	def __data_generation(self, batch_ids):
		X, y = [], []
		for case_id in batch_ids:
			is_aug = case_id in self.aug_ids
			input_dir = AUG_INPUT_PATH if is_aug else INPUT_PATH
			mask_dir = AUG_MASK_PATH if is_aug else MASK_PATH

			input_files = sorted([f for f in os.listdir(input_dir)
								if f.startswith(f'slice_{case_id}') and f.endswith('.png')])

			for f in input_files:
				img_path = os.path.join(input_dir, f)
				mask_path = os.path.join(mask_dir, f)

				X.append(load_and_preprocess(img_path))
				y.append(load_and_preprocess(mask_path, is_mask=True))

		return np.expand_dims(np.array(X), -1), np.array(y)

def create_model():
	inputs = Input((IMG_SIZE, IMG_SIZE, 1))

	# Encoder with reduced filters
	x = conv_block(inputs, 32)
	skip1 = x
	x = MaxPooling2D()(x)

	x = conv_block(x, 64)
	skip2 = x
	x = MaxPooling2D()(x)

	x = conv_block(x, 128)
	skip3 = x
	x = MaxPooling2D()(x)

	x = conv_block(x, 256)
	skip4 = x
	x = MaxPooling2D()(x)

	# Bridge
	x = conv_block(x, 512)

	# Decoder with attention
	x = Conv2DTranspose(256, 3, strides=2, padding='same')(x)
	x = attention_gate(skip4, x, 256)
	x = concatenate([x, skip4])
	x = conv_block(x, 256)

	x = Conv2DTranspose(128, 3, strides=2, padding='same')(x)
	x = attention_gate(skip3, x, 128)
	x = concatenate([x, skip3])
	x = conv_block(x, 128)

	x = Conv2DTranspose(64, 3, strides=2, padding='same')(x)
	x = attention_gate(skip2, x, 64)
	x = concatenate([x, skip2])
	x = conv_block(x, 64)

	x = Conv2DTranspose(32, 3, strides=2, padding='same')(x)
	x = attention_gate(skip1, x, 32)
	x = concatenate([x, skip1])
	x = conv_block(x, 32)

	outputs = Conv2D(1, 1, activation='sigmoid')(x)

	model = Model(inputs, outputs)

	model.compile(
		optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNINGRATE),
		loss=dice_loss,
		metrics=['accuracy', dice_coeff, iou]
	)

	return model

def main():
	# GPU memory growth
	gpus = tf.config.experimental.list_physical_devices('GPU')
	if gpus:
		for gpu in gpus:
			tf.config.experimental.set_memory_growth(gpu, True)

	case_ids = get_case_ids(INPUT_PATH)
	aug_case_ids = get_case_ids(AUG_INPUT_PATH) if os.path.exists(AUG_INPUT_PATH) else []

	train_ids, test_ids = train_test_split(case_ids, test_size=0.2, random_state=42)
	train_ids, val_ids = train_test_split(train_ids, test_size=0.2, random_state=42)

	print(f"Train: {len(train_ids)}, Val: {len(val_ids)}, Test: {len(test_ids)}, Aug: {len(aug_case_ids)}")

	train_gen = DataGenerator(train_ids, aug_ids=aug_case_ids)
	val_gen = DataGenerator(val_ids, shuffle=False)
	test_gen = DataGenerator(test_ids, shuffle=False)

	model = create_model()

	print("Model Summary: ", model.summary())

	callbacks = [
		ModelCheckpoint('best_model.h5', monitor='val_dice_coeff', mode='max',
					   save_best_only=True, verbose=1),
		EarlyStopping(monitor='val_loss', patience=EARLYSTOPPING, restore_best_weights=True, verbose=1),
		ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)
	]

	model.fit(
		train_gen,
		validation_data=val_gen,
		epochs=EPOCHS,
		callbacks=callbacks,
		workers=4,
		use_multiprocessing=True
	)

	results = model.evaluate(test_gen)
	print("\nTest Results:")
	print(f"Loss: {results[0]:.4f}")
	print(f"Accuracy: {results[1]:.4f}")
	print(f"Dice Score: {results[2]:.4f}")
	print(f"IoU: {results[3]:.4f}")

if __name__ == "__main__":
	main()





Table 4.1: Comparison of Dice Scores: Benchmark vs Experiment Results
Benchmark Results (For Lesion Only)
Case Image Format Model Type Test Dice Score
1 .nii U-Net 0.6675
Experiment Results (For Lesion Only)
Case Image Format Analysis Type Test Dice Score
1 PNG Attention U-Net 0.6651
2 PNG + augmentation Attention U-Net 0.7307
3 PNG + augmentation U-Net 0.7451





I have shared my previous semester's work summary and the code I wrote. This semester I should do something on top of my previous semester's work as part of my Mtech research. I am currently in my final semester and they except me to contribute something unique (never achieved before) to research. My domain is healthcare: brain lesion segmentation. I want you to go go through my work's summary, my code and also the result I was able to achieve and then come up with various augmentation strategies (a combination of existing strategies or something entirely new) which are easy to implement but also should contribute to research (should have never been done before). First ponder over various augmentation techniques that could be further applied over this augmented dataset that I had created in my previous semester's work then come to a final conclusion about the augmentation technique that we will be implementing for this semester, it should be new and easy to implement as well.
