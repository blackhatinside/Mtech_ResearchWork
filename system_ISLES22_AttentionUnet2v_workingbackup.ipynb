{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c74a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "#from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger\n",
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ae7c7e-b954-4d5a-a598-3d0b3852ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(path):\n",
    "    directories = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "    ids = []\n",
    "    id_startindex = directories[0].find(\"sub\")\n",
    "    for i in range(len(directories)):\n",
    "        ids.append(directories[i][id_startindex:])\n",
    "    return sorted(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983b5cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Folders Inside Dataset:  6\n",
      "No of Folders Inside Training:  250\n",
      "No of Folders Inside Ground Truth:  251\n"
     ]
    }
   ],
   "source": [
    "PATH_DATASET = \"/home/user/Tf_script/dataset/ISLES_2022/\"\n",
    "PATH_RAWDATA = \"/home/user/Tf_script/dataset/ISLES_2022/rawdata/\"\n",
    "PATH_DERIVATIVES = \"/home/user/Tf_script/dataset/ISLES_2022/derivatives/\"\n",
    "\n",
    "print(\"No of Folders Inside Dataset: \", len(os.listdir(PATH_DATASET)))\n",
    "# print(\"Folders Inside Dataset: \", os.listdir(\"../input/isles2022small/ISLES2022/\"))\n",
    "print(\"No of Folders Inside Training: \", len(os.listdir(PATH_RAWDATA)))\n",
    "# print(\"Folders Inside Training: \", os.listdir(\"../input/isles2022small/ISLES2022/rawdata/\"))\n",
    "print(\"No of Folders Inside Ground Truth: \", len(os.listdir(PATH_DERIVATIVES)))\n",
    "# print(\"Folders Inside Ground Truth: \", os.listdir(\"../input/isles2022small/ISLES2022/derivatives/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae7c6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of train_ids:  250\n",
      "no of mask_ids:  250\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET_PATH = PATH_RAWDATA\n",
    "train_ids = get_ids(TRAIN_DATASET_PATH)\n",
    "TRAINMask_DATASET_PATH = PATH_DERIVATIVES\n",
    "mask_ids = get_ids(TRAINMask_DATASET_PATH)\n",
    "\n",
    "print(\"no of train_ids: \", len(train_ids))\n",
    "# print(\"train_ids: \", train_ids)\n",
    "print(\"no of mask_ids: \", len(mask_ids))\n",
    "# print(\"mask_ids: \", mask_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f0f615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, validate, test:  [191, 25, 34]\n"
     ]
    }
   ],
   "source": [
    "train_test_ids, val_ids,train_test_mask, val_mask = train_test_split(train_ids,mask_ids,test_size=0.1) \n",
    "train_ids,  test_ids, train_mask , test_mask = train_test_split(train_test_ids,train_test_mask,test_size=0.15)\n",
    "\n",
    "tvt_ids = [train_ids, val_ids, test_ids]\n",
    "print(\"train, validate, test: \", list(map(len, tvt_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da0aa998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the performance metrics\n",
    "def dice_coeff(y_true,y_pred):\n",
    "    y_true_new = K.flatten(y_true)\n",
    "    y_pred_new = K.flatten(y_pred)\n",
    "    denominator = K.sum(y_true_new) + K.sum(y_pred_new)\n",
    "    numerator = K.sum(y_true_new * y_pred_new)\n",
    "    return (2*numerator + 1)/(denominator+1)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        \n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def dsc(y_true, y_pred):\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    fn = K.sum(y_true * neg_y_pred)\n",
    "    fp = K.sum(neg_y_true * y_pred)\n",
    "    dsc = (2*tp) / ((2*tp) + fn + fp)\n",
    "    return dsc    \n",
    "\n",
    "def iou(y_true,y_pred):\n",
    "    intersec = K.sum(y_true * y_pred)\n",
    "    union = K.sum(y_true + y_pred)\n",
    "    iou = (intersec + 0.1) / (union- intersec + 0.1)\n",
    "    return iou\n",
    "\n",
    "def dice_score(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2.0 * intersection + 1e-5) / (union + 1e-5)\n",
    "    return dice\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 -dice_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6be59536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VOLUME_SLICES = 20\n",
    "#VOLUME_START_AT = 5\n",
    "IMG_SIZE=112\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 1, shuffle=False):\n",
    "       \n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        #X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        #y = np.zeros((self.batch_size*VOLUME_SLICES, 112, 112))\n",
    "        #Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):           \n",
    "            \n",
    "            \n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "            data_path = os.path.join(case_path + '/ses-0001/dwi', f'{i}_ses-0001_dwi.nii.gz');\n",
    "            dwi = nib.load(data_path).get_fdata()\n",
    "            #dwi=dwi.astype(np.uint8)\n",
    "            dwi=scaler.fit_transform(dwi.reshape(-1, dwi.shape[-1])).reshape(dwi.shape)\n",
    "            slices = dwi.shape[2]\n",
    "            X = np.zeros((slices, 112,112, 1))\n",
    "            #X=X.astype(np.float32)\n",
    "\n",
    "            case_path2 = os.path.join(TRAINMask_DATASET_PATH, i)\n",
    "            data_path_2 = os.path.join(case_path2 + '/ses-0001', f'{i}_ses-0001_msk.nii.gz');\n",
    "            msk = nib.load(data_path_2).get_fdata()\n",
    "            #msk=msk.astype(np.uint8)\n",
    "            msk_slices = msk.shape[2]\n",
    "            y = np.zeros((msk_slices, 112,112))\n",
    "            #y=y.astype(np.float32)  \n",
    "\n",
    "            \n",
    "            for j in range(slices):\n",
    "                X[j,:,:,0] = cv2.resize(dwi[:,:,j+0], (IMG_SIZE, IMG_SIZE));\n",
    "                X=X.astype(np.float32)\n",
    "                #X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "                y[j] = cv2.resize(msk[:,:,j+0],(112,112));\n",
    "                #y=y.astype(np.float32) \n",
    "#                 y[j] = msk[:,:,j+VOLUME_START_AT];\n",
    "       \n",
    "        #mask = tf.one_hot(y, 2)\n",
    "        #print(X.shape)\n",
    "        #print(X.max())\n",
    "        \n",
    "        #return X/np.max(X), mask\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f6aab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, validate, test:  [191, 25, 34]\n"
     ]
    }
   ],
   "source": [
    "training_generator = DataGenerator(train_ids)\n",
    "val_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)\n",
    "\n",
    "tvt_generator = [training_generator, val_generator, test_generator]\n",
    "print(\"train, validate, test: \", list(map(len, tvt_generator)))\n",
    "# test_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c52c7b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inp,filters):\n",
    "    x=Conv2D(filters,(3,3),padding='same',activation='relu')(inp)\n",
    "    x=Conv2D(filters,(3,3),padding='same')(x)\n",
    "    x=BatchNormalization(axis=3)(x)\n",
    "    x=Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(inp,filters):\n",
    "    x=conv_block(inp,filters)\n",
    "    p=MaxPooling2D(pool_size=(2,2))(x)\n",
    "    return x,p\n",
    "\n",
    "def attention_block(l_layer,h_layer): #Attention Block\n",
    "    phi=Conv2D(h_layer.shape[-1],(1,1),padding='same')(l_layer)\n",
    "    theta=Conv2D(h_layer.shape[-1],(1,1),strides=(2,2),padding='same')(h_layer)\n",
    "    x=tf.keras.layers.add([phi,theta])\n",
    "    x=Activation('relu')(x)\n",
    "    x=Conv2D(1,(1,1),padding='same',activation='sigmoid')(x)\n",
    "    x=UpSampling2D(size=(2,2))(x)\n",
    "    x=tf.keras.layers.multiply([h_layer,x])\n",
    "    x=BatchNormalization(axis=3)(x)\n",
    "    return x\n",
    "    \n",
    "def decoder_block(inp,filters,concat_layer):\n",
    "    x=Conv2DTranspose(filters,(2,2),strides=(2,2),padding='same')(inp)\n",
    "    #concat_layer=attention_block(inp,concat_layer)\n",
    "    x=concatenate([x,concat_layer])\n",
    "    x=conv_block(x,filters)\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7c5c1ad-199d-4534-973b-f830d87d75ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_EPOCH = 30\n",
    "VAL_PATIENCE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "281751b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 17:02:46.428106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13937 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:19:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AttentionUnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 112, 112, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 112, 112, 64  640         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 112, 112, 64  36928       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 112, 112, 64  256        ['conv2d_1[0][0]']               \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 112, 112, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 56, 56, 64)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 56, 56, 128)  73856       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 56, 56, 128)  147584      ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 56, 56, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 128)  0          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 28, 28, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 28, 28, 256)  590080      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 28, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 28, 256)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 256)  0          ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 14, 14, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 14, 14, 512)  2359808     ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 14, 14, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 14, 14, 512)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 512)   0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 7, 7, 1024)   4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 7, 7, 1024)   9438208     ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 7, 7, 1024)  4096        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 7, 7, 1024)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 14, 14, 512)  2097664    ['activation_4[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 14, 14, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 14, 14, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 14, 14, 512)  2359808     ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 14, 14, 512)  2048       ['conv2d_11[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 14, 14, 512)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 28, 28, 256)  524544     ['activation_5[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 28, 28, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 28, 28, 256)  1179904     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 28, 28, 256)  590080      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 28, 256)  1024       ['conv2d_13[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 28, 28, 256)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 56, 56, 128)  131200     ['activation_6[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 56, 56, 256)  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 56, 56, 128)  295040      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 56, 56, 128)  147584      ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 56, 56, 128)  512        ['conv2d_15[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 112, 112, 64  32832      ['activation_7[0][0]']           \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 112, 112, 12  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                8)                                'activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 112, 112, 64  73792       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 112, 112, 64  36928       ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 112, 112, 64  256        ['conv2d_17[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 112, 112, 64  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 112, 112, 1)  65          ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,042,369\n",
      "Trainable params: 31,036,481\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs=Input((112,112,1))\n",
    "#inputfloat=Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "d1,p1=encoder_block(inputs,64)\n",
    "d2,p2=encoder_block(p1,128)\n",
    "d3,p3=encoder_block(p2,256)\n",
    "d4,p4=encoder_block(p3,512)\n",
    "b1=conv_block(p4,1024)\n",
    "e2=decoder_block(b1,512,d4)\n",
    "e3=decoder_block(e2,256,d3)\n",
    "e4=decoder_block(e3,128,d2)\n",
    "e5=decoder_block(e4,64,d1)\n",
    "\n",
    "outputs = Conv2D(1, (1,1),activation=\"sigmoid\")(e5)\n",
    "model=Model(inputs=[inputs], outputs=[outputs],name='AttentionUnet')\n",
    "\n",
    "model.compile(\n",
    "    loss=dice_loss, \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "    metrics = ['accuracy', dice_coeff,dice_score,iou, precision] \n",
    ")\n",
    "#model.compile(loss=BinaryFocalLoss(gamma=2), optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics = ['accuracy', dice_coeff, iou] )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6671cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 17:02:47.288262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-08-09 17:02:51.651316: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-08-09 17:02:55.267346: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f231c24bcd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-09 17:02:55.267372: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2024-08-09 17:02:55.270868: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-09 17:02:55.405088: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - ETA: 0s - loss: 0.9659 - accuracy: 0.8855 - dice_coeff: 0.0351 - dice_score: 0.0351 - iou: 0.0187 - precision: 0.0329"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 17:06:13.003497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.21360, saving model to DiceLoss_ISLES22_2DAttention_wts.h5\n",
      "191/191 [==============================] - 210s 975ms/step - loss: 0.9659 - accuracy: 0.8855 - dice_coeff: 0.0351 - dice_score: 0.0351 - iou: 0.0187 - precision: 0.0329 - val_loss: 0.9977 - val_accuracy: 0.2136 - val_dice_coeff: 0.0033 - val_dice_score: 0.0033 - val_iou: 0.0016 - val_precision: 0.0014\n",
      "Epoch 2/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.8749 - accuracy: 0.9763 - dice_coeff: 0.1382 - dice_score: 0.1381 - iou: 0.0866 - precision: 0.1666\n",
      "Epoch 2: val_accuracy improved from 0.21360 to 0.87200, saving model to DiceLoss_ISLES22_2DAttention_wts.h5\n",
      "191/191 [==============================] - 62s 325ms/step - loss: 0.8749 - accuracy: 0.9763 - dice_coeff: 0.1382 - dice_score: 0.1381 - iou: 0.0866 - precision: 0.1666 - val_loss: 0.9875 - val_accuracy: 0.8720 - val_dice_coeff: 0.0188 - val_dice_score: 0.0188 - val_iou: 0.0099 - val_precision: 0.0098\n",
      "Epoch 3/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.9964 - dice_coeff: 0.3434 - dice_score: 0.3428 - iou: 0.2413 - precision: 0.4312\n",
      "Epoch 3: val_accuracy improved from 0.87200 to 0.99835, saving model to DiceLoss_ISLES22_2DAttention_wts.h5\n",
      "191/191 [==============================] - 62s 325ms/step - loss: 0.6828 - accuracy: 0.9964 - dice_coeff: 0.3434 - dice_score: 0.3428 - iou: 0.2413 - precision: 0.4312 - val_loss: 0.8247 - val_accuracy: 0.9983 - val_dice_coeff: 0.2057 - val_dice_score: 0.2051 - val_iou: 0.1333 - val_precision: 0.1960\n",
      "Epoch 4/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.9971 - dice_coeff: 0.3948 - dice_score: 0.3938 - iou: 0.2816 - precision: 0.5218\n",
      "Epoch 4: val_accuracy improved from 0.99835 to 0.99922, saving model to DiceLoss_ISLES22_2DAttention_wts.h5\n",
      "191/191 [==============================] - 62s 326ms/step - loss: 0.6275 - accuracy: 0.9971 - dice_coeff: 0.3948 - dice_score: 0.3938 - iou: 0.2816 - precision: 0.5218 - val_loss: 0.7656 - val_accuracy: 0.9992 - val_dice_coeff: 0.2652 - val_dice_score: 0.2645 - val_iou: 0.1771 - val_precision: 0.3909\n",
      "Epoch 5/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.5965 - accuracy: 0.9973 - dice_coeff: 0.4285 - dice_score: 0.4271 - iou: 0.3120 - precision: 0.5555\n",
      "Epoch 5: val_accuracy improved from 0.99922 to 0.99930, saving model to DiceLoss_ISLES22_2DAttention_wts.h5\n",
      "191/191 [==============================] - 63s 329ms/step - loss: 0.5965 - accuracy: 0.9973 - dice_coeff: 0.4285 - dice_score: 0.4271 - iou: 0.3120 - precision: 0.5555 - val_loss: 0.6161 - val_accuracy: 0.9993 - val_dice_coeff: 0.4051 - val_dice_score: 0.3960 - val_iou: 0.2862 - val_precision: 0.5925\n",
      "Epoch 6/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.9975 - dice_coeff: 0.4512 - dice_score: 0.4490 - iou: 0.3292 - precision: 0.5741\n",
      "Epoch 6: val_accuracy improved from 0.99930 to 0.99932, saving model to DiceLoss_ISLES22_2DAttention_wts.h5\n",
      "191/191 [==============================] - 61s 317ms/step - loss: 0.5740 - accuracy: 0.9975 - dice_coeff: 0.4512 - dice_score: 0.4490 - iou: 0.3292 - precision: 0.5741 - val_loss: 0.6278 - val_accuracy: 0.9993 - val_dice_coeff: 0.4043 - val_dice_score: 0.3962 - val_iou: 0.2894 - val_precision: 0.4762\n",
      "Epoch 7/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.5597 - accuracy: 0.9976 - dice_coeff: 0.4662 - dice_score: 0.4652 - iou: 0.3455 - precision: 0.5775\n",
      "Epoch 7: val_accuracy did not improve from 0.99932\n",
      "191/191 [==============================] - 61s 319ms/step - loss: 0.5597 - accuracy: 0.9976 - dice_coeff: 0.4662 - dice_score: 0.4652 - iou: 0.3455 - precision: 0.5775 - val_loss: 0.6310 - val_accuracy: 0.9992 - val_dice_coeff: 0.3835 - val_dice_score: 0.3797 - val_iou: 0.2663 - val_precision: 0.5193\n",
      "Epoch 8/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.5436 - accuracy: 0.9977 - dice_coeff: 0.4817 - dice_score: 0.4805 - iou: 0.3606 - precision: 0.5894\n",
      "Epoch 8: val_accuracy did not improve from 0.99932\n",
      "191/191 [==============================] - 59s 309ms/step - loss: 0.5436 - accuracy: 0.9977 - dice_coeff: 0.4817 - dice_score: 0.4805 - iou: 0.3606 - precision: 0.5894 - val_loss: 0.6299 - val_accuracy: 0.9993 - val_dice_coeff: 0.3953 - val_dice_score: 0.3934 - val_iou: 0.2812 - val_precision: 0.3900\n",
      "Epoch 9/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.9977 - dice_coeff: 0.4937 - dice_score: 0.4883 - iou: 0.3673 - precision: 0.5936\n",
      "Epoch 9: val_accuracy improved from 0.99932 to 0.99938, saving model to DiceLoss_ISLES22_2DAttention_wts.h5\n",
      "191/191 [==============================] - 61s 321ms/step - loss: 0.5347 - accuracy: 0.9977 - dice_coeff: 0.4937 - dice_score: 0.4883 - iou: 0.3673 - precision: 0.5936 - val_loss: 0.5850 - val_accuracy: 0.9994 - val_dice_coeff: 0.4435 - val_dice_score: 0.4372 - val_iou: 0.3247 - val_precision: 0.5092\n",
      "Epoch 10/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.9977 - dice_coeff: 0.5030 - dice_score: 0.5008 - iou: 0.3784 - precision: 0.6188\n",
      "Epoch 10: val_accuracy did not improve from 0.99938\n",
      "191/191 [==============================] - 59s 307ms/step - loss: 0.5216 - accuracy: 0.9977 - dice_coeff: 0.5030 - dice_score: 0.5008 - iou: 0.3784 - precision: 0.6188 - val_loss: 0.7647 - val_accuracy: 0.9980 - val_dice_coeff: 0.2653 - val_dice_score: 0.2645 - val_iou: 0.1740 - val_precision: 0.2070\n",
      "Epoch 11/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.9978 - dice_coeff: 0.5206 - dice_score: 0.5177 - iou: 0.3952 - precision: 0.6524\n",
      "Epoch 11: val_accuracy did not improve from 0.99938\n",
      "191/191 [==============================] - 61s 317ms/step - loss: 0.5025 - accuracy: 0.9978 - dice_coeff: 0.5206 - dice_score: 0.5177 - iou: 0.3952 - precision: 0.6524 - val_loss: 0.6030 - val_accuracy: 0.9993 - val_dice_coeff: 0.4166 - val_dice_score: 0.4099 - val_iou: 0.2979 - val_precision: 0.5965\n",
      "Epoch 12/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.4822 - accuracy: 0.9979 - dice_coeff: 0.5382 - dice_score: 0.5367 - iou: 0.4126 - precision: 0.6418\n",
      "Epoch 12: val_accuracy improved from 0.99938 to 0.99942, saving model to DiceLoss_ISLES22_2DAttention_wts.h5\n",
      "191/191 [==============================] - 65s 338ms/step - loss: 0.4822 - accuracy: 0.9979 - dice_coeff: 0.5382 - dice_score: 0.5367 - iou: 0.4126 - precision: 0.6418 - val_loss: 0.5409 - val_accuracy: 0.9994 - val_dice_coeff: 0.4847 - val_dice_score: 0.4789 - val_iou: 0.3624 - val_precision: 0.5300\n",
      "Epoch 13/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.9978 - dice_coeff: 0.5290 - dice_score: 0.5228 - iou: 0.3992 - precision: 0.6520\n",
      "Epoch 13: val_accuracy did not improve from 0.99942\n",
      "191/191 [==============================] - 60s 315ms/step - loss: 0.4962 - accuracy: 0.9978 - dice_coeff: 0.5290 - dice_score: 0.5228 - iou: 0.3992 - precision: 0.6520 - val_loss: 0.6136 - val_accuracy: 0.9992 - val_dice_coeff: 0.4160 - val_dice_score: 0.4141 - val_iou: 0.2976 - val_precision: 0.3946\n",
      "Epoch 14/15\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.9980 - dice_coeff: 0.5578 - dice_score: 0.5510 - iou: 0.4297 - precision: 0.6600"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiceLoss_ISLES22_2DAttention_wts.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m     10\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     11\u001b[0m     patience\u001b[38;5;241m=\u001b[39mVAL_PATIENCE, \n\u001b[1;32m     12\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     13\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m att_unet_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVAL_EPOCH\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py:1729\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1715\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1716\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1717\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1728\u001b[0m     )\n\u001b[0;32m-> 1729\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1742\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1744\u001b[0m }\n\u001b[1;32m   1745\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/keras/engine/training.py:2072\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2070\u001b[0m ):\n\u001b[1;32m   2071\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2072\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2074\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    935\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/adi_ani_tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'DiceLoss_ISLES22_2DAttention_wts.h5', \n",
    "    monitor='val_accuracy', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=VAL_PATIENCE, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "att_unet_history = model.fit(\n",
    "    training_generator, \n",
    "    steps_per_epoch=len(train_ids),\n",
    "    validation_data=val_generator, \n",
    "    callbacks= [checkpoint,early_stop],\n",
    "    epochs=VAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d55f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wt=model.predict(test_generator)\n",
    "test_wt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478527f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_generator, steps=len(test_ids))\n",
    "print(\"Test loss: \",results[0])\n",
    "print(\"Test Dice: \",results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e9a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(3,3))\n",
    "ax.imshow(test_wt[10,:,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58999324",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_thresholded = test_wt > 0.4\n",
    "fig, ax = plt.subplots(1,1, figsize=(3,3))\n",
    "ax.imshow(y_pred_thresholded[10,:,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33db106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the Dice coefficient\n",
    "def dice_coeff(y_true,y_pred):\n",
    "    # Ensure both tensors are of type float32\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true_new = K.flatten(y_true)\n",
    "    y_pred_new = K.flatten(y_pred)\n",
    "    denominator = K.sum(y_true_new) + K.sum(y_pred_new)\n",
    "    if denominator == 0.0:\n",
    "        return 1.0\n",
    "    numerator = K.sum(y_true_new * y_pred_new)\n",
    "    return (2.0*numerator)/(denominator)\n",
    "\n",
    "def iou(y_true,y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersec = K.sum(y_true * y_pred)\n",
    "    union = K.sum(y_true + y_pred)\n",
    "    if union == 0.0:\n",
    "        return 1.0\n",
    "    iou = (intersec) / (union- intersec)\n",
    "    return iou\n",
    "\n",
    "# Initialize lists to store loss and metric values\n",
    "loss_values = []\n",
    "dice_values = []\n",
    "iou_values = []\n",
    "\n",
    "# Loop through the test generator\n",
    "for batch_x, batch_y in test_generator:\n",
    "    # Predict the output for the batch\n",
    "    #print(batch_y.shape)\n",
    "    mask_image = np.expand_dims(batch_y, axis=-1)\n",
    "    y_predwts = model.predict(batch_x)\n",
    "    #y_predwt = y_predwts\n",
    "    #print('y_pred',y_predwts.shape)\n",
    "    #y_pred_thresholded = np.where(y_predwts >= 0.5, 1.0, 0.0).astype(np.float32)#binary\n",
    "    y_pred = np.where(y_predwts < 0.2, 0.0, y_predwts).astype(np.float32)#relu\n",
    "    y_pred_thresholded = y_pred \n",
    "    \n",
    "    # Loop through each sample in the batch\n",
    "    for i in range(len(batch_x)):\n",
    "        # Compute the loss and metrics for each sample\n",
    "        #loss = compute_loss(batch_y[i], y_pred[i])\n",
    "        dice = dice_coeff(batch_y[i], y_pred_thresholded[i])\n",
    "        iou_value = iou(batch_y[i], y_pred_thresholded[i])\n",
    "    \n",
    "        # Store the computed values\n",
    "        #loss_values.append(loss)\n",
    "        dice_values.append(dice)\n",
    "        iou_values.append(iou_value)\n",
    "\n",
    "    \n",
    "    # Stop if we've processed all steps\n",
    "    if len(loss_values) >= len(test_generator):\n",
    "        break\n",
    "\n",
    "# Compute the average loss and metrics\n",
    "#average_loss = np.mean(loss_values)\n",
    "average_dice = np.mean(dice_values)\n",
    "average_iou = np.mean(iou_values)\n",
    "\n",
    "# Convert the list to a tensor for easy aggregation\n",
    "hd_distances = tf.stack(hausdorff_distance_value)\n",
    "\n",
    "#Exclude slices with inf values from the calculation\n",
    "valid_hd_distances = tf.boolean_mask(hd_distances, tf.math.is_finite(hd_distances))\n",
    "mean_hd = tf.reduce_mean(valid_hd_distances)\n",
    "max_hd = tf.reduce_max(valid_hd_distances)\n",
    "\n",
    "#print(\"Average test loss: \", average_loss)\n",
    "print(\"Average test dice: \", average_dice)\n",
    "print(\"Average test IoU: \", average_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths.\n",
    "isles_data_dir = '/home/user/Tf_script/dataset/ISLES_2022/'\n",
    "example_case = 19\n",
    "\n",
    "# Set images path.\n",
    "dwi_path = os.path.join(isles_data_dir, 'rawdata', 'sub-strokecase{}'.format(\"%04d\" %example_case), 'ses-0001', 'dwi/'\n",
    "                    'sub-strokecase{}_ses-0001_dwi.nii.gz'.format(\"%04d\" % example_case))\n",
    "mask_path = os.path.join(isles_data_dir, 'derivatives', 'sub-strokecase{}'.format(\"%04d\" %example_case), 'ses-0001', 'sub-strokecase{}_ses-0001_msk.nii.gz'.format(\"%04d\" % example_case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image data.\n",
    "dwi_image = nib.load(dwi_path).get_fdata()\n",
    "mask_image = nib.load(mask_path).get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eefe0c-8fd4-4c20-872f-6c2863bfb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def img_resize(img, dims):\n",
    "#     return cv2.resize(img[:,:], dims)\n",
    "\n",
    "img_resize = lambda img, dims: cv2.resize(img[:,:], dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f345656",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_image=img_resize(dwi_image, (112, 112))\n",
    "mask_image=img_resize(mask_image, (112, 112))\n",
    "dwi_image.shape\n",
    "mask_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c89bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "slice2show=31\n",
    "ax1.imshow(dwi_image[:,:,slice2show], cmap='gray')\n",
    "ax1.set_title('Dwi')\n",
    "ax1.set_axis_off()\n",
    "\n",
    "\n",
    "# Show DWI image w/overlayed mask.\n",
    "ax2.imshow(mask_image[:,:,slice2show], cmap='gray')\n",
    "#ax2.imshow(mask_image[:,:,slice2show], alpha=0.5, cmap='copper')\n",
    "ax2.set_title('GT')\n",
    "ax2.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44568cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_image=scaler.fit_transform(dwi_image.reshape(-1, dwi_image.shape[-1])).reshape(dwi_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46620c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((72,112,112,1))\n",
    "for j in range(72):\n",
    "    X[j,:,:,0] =dwi_image[:,:,j]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c04741",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_wt=model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8023f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(3,3))\n",
    "ax.imshow(pred_wt[31,:,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_thresholded = pred_wt > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(3,3))\n",
    "ax.imshow(y_pred_thresholded[31,:,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c2c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    total = np.sum(y_true) + np.sum(y_pred)\n",
    "    dice = (2 * intersection +1 ) / (total + 1)  # Adding a small epsilon to avoid division by zero\n",
    "    #dice = np.mean(dice)\n",
    "    dice = round(dice, 3)\n",
    "    return dice\n",
    "\n",
    "def iou(y_true,y_pred):\n",
    "    intersec = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true + y_pred)\n",
    "    iou = (intersec + 1) / (union- intersec + 1)\n",
    "    iou = round(iou, 3)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264088e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef180799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory to save the plot images\n",
    "output_directory = './output/ISLESfolder'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Plot each slice along with the original mask and predicted mask\n",
    "for i in range(5,60):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot the original image\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(dwi_image[:,:,i], cmap='gray')\n",
    "    plt.title('Input Slice')\n",
    "\n",
    "    # Plot the original mask\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(mask_image[:,:,i], cmap='gray')\n",
    "    plt.title('Original Mask')\n",
    "\n",
    "    # Plot the predicted mask\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(pred_wt[i,:,:,:], cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    \n",
    "    # Plot the predicted mask\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(y_pred_thresholded[i,:,:,:], cmap='gray')\n",
    "    plt.title('Thresholed Mask')\n",
    "\n",
    "    #plt.suptitle(f\"Slice: {i+1}\")\n",
    "    dice = dice_score(mask_image[:,:,i], y_pred_thresholded[i,:,:,:])\n",
    "    Iou = iou(mask_image[:,:,i], y_pred_thresholded[i,:,:,:])\n",
    "    plt.suptitle(f\"Sample_19_Slice_00{i}  ,Dice Score:{dice}  ,IOU:{Iou}\")\n",
    "    #print(f'Dice Score: {dice}')\n",
    "    #plt.savefig(f'plot_{i}.png')\n",
    "    #plt.show()\n",
    "        \n",
    "    # Save the plot image in the output folder\n",
    "    output_filename = f'Sample_19_Slice_00{i}.png'\n",
    "    output_path = os.path.join(output_directory, output_filename)\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()\n",
    "    plt.close()  # Close the figure to release memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
